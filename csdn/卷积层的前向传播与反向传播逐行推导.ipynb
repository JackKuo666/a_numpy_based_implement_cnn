{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.前言\n",
    "### 这里是第二个卷积层:\n",
    "#### 正向传播输入是[10 32 14 14]，输出是[10 16 14 14],w是[16 32 3 3],b是[16]\n",
    "#### 反向传播输入是top_diff=[10 16 14 14]，输出是bottom_diff=[10 32 14 14],w_diff=[16 32 3 3], b_diff = [16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.定义卷积函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 环境：python 3.6；numpy\n",
    "import numpy as np\n",
    "\n",
    "class ConvLayer(object):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, lr=0.01, stride = 1, pad = 1, momentum=0.9, reg = 0.75, name='Conv'):\n",
    "        self.w = np.random.randn(out_channel,in_channel, kernel_size, kernel_size)    #w初值设置，随机产生标准正太分布范围内的数\n",
    "        self.b = np.random.randn(out_channel)\n",
    "        #w_shape = (out_channel,in_channel, kernel_size, kernel_size)\n",
    "        self.layer_name = name\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.reg = reg\n",
    "\n",
    "        self.prev_gradient_w = np.zeros_like(self.w)\n",
    "        self.prev_gradient_b = np.zeros_like(self.b)\n",
    "\n",
    "    def forward(self, in_data):\n",
    "        self.out = None\n",
    "        N, C, H, W = in_data.shape\n",
    "        F, _, HH, WW = self.w.shape                                            #F是out_channel,HH是kernel_size,ww是kernel_size;\n",
    "        stride, pad = self.stride, self.pad\n",
    "        H_out = int(1 + (H + 2 * pad - HH) / stride)                           #计算纵向卷积需要滑几步\n",
    "        W_out = int(1 + (W + 2 * pad - WW) / stride)                           #计算横向卷积需要滑几步\n",
    "        self.out = np.zeros((N , F , H_out, W_out))\n",
    "\n",
    "        in_data_pad = np.pad(in_data, ((0,), (0,), (pad,), (pad,)), mode='constant', constant_values=0) #边缘填充，这里上下左右各填一个像素\n",
    "        for i in range(H_out):\n",
    "            for j in range(W_out):\n",
    "                in_data_pad_masked = in_data_pad[:, :, i*stride:i*stride+HH, j*stride:j*stride+WW]\n",
    "                for k in range(F):\n",
    "                    self.out[:, k , i, j] = np.sum(in_data_pad_masked * self.w[k, :, :, :], axis=(1,2,3))+ self.b[k] #注意：这里比原版加了一个+ self.b[k]\n",
    "\n",
    "        self.bottom_val = in_data\n",
    "        return self.out ,self.w ,self.b\n",
    "        # 注意：这里我们返回更多的变量，方便调试\n",
    "\n",
    "    def backward(self, residual):\n",
    "        N, C, H, W = self.bottom_val.shape\n",
    "        F, _, HH, WW = self.w.shape\n",
    "        stride, pad = self.stride, self.pad\n",
    "        H_out = int(1 + (H + 2 * pad - HH) / stride)\n",
    "        W_out = int(1 + (W + 2 * pad - WW) / stride)\n",
    "\n",
    "        x_pad = np.pad(self.bottom_val, ((0,), (0,), (pad,), (pad,)), mode='constant', constant_values=0)\n",
    "        dx = np.zeros_like(self.bottom_val)\n",
    "        dx_pad = np.zeros_like(x_pad)\n",
    "        dw = np.zeros_like(self.w)\n",
    "        # db = np.zeros_like(self.b)\n",
    "\n",
    "        db = np.sum(residual, axis=(0, 2, 3))\n",
    "\n",
    "        x_pad = np.pad(self.bottom_val, ((0,), (0,), (pad,), (pad,)), mode='constant', constant_values=0)\n",
    "        for i in range(H_out):\n",
    "            for j in range(W_out):\n",
    "                x_pad_masked = x_pad[:, :, i * stride:i * stride + HH, j * stride:j * stride + WW]\n",
    "                for k in range(F):  # compute dw\n",
    "                    dw[k, :, :, :] += np.sum(x_pad_masked * (residual[:, k, i, j])[:, None, None, None], axis=0)\n",
    "                for n in range(N):  # compute dx_pad\n",
    "                    temp_w = np.rot90(self.w,2,(2,3))#这种写法不旋转\n",
    "                    dx_pad[n, :, i * stride:i * stride + HH, j * stride:j * stride + WW] += np.sum((self.w[:, :, :, :] * (residual[n, :, i,j])[:, None, None, None]), axis=0)\n",
    "        dx[:,:,:,:] = dx_pad[:, :, pad:-pad, pad:-pad]\n",
    "        self.w -= self.lr * (dw + self.prev_gradient_w * self.reg)\n",
    "        self.b -= self.lr * db\n",
    "        self.prev_gradient_w = self.w\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 32, 14, 14)\n",
      "(16, 32, 3, 3)\n",
      "(16,)\n",
      "(10, 16, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "# 前向传播\n",
    "in_data = np.load(\"./data_pic/data_3_relu1[10-32-14-14].npy\")\n",
    "out_data,con_w ,con_b = ConvLayer(32, 16, 3, 1e-5).forward(in_data)\n",
    "print (in_data.shape)\n",
    "print (con_w.shape)\n",
    "print (con_b.shape)\n",
    "print (out_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.前向传播逐行推导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卷积层的输入的shape是：\n",
      "(10, 32, 14, 14)\n",
      "\n",
      "卷积层的输入边缘填充之后的shape是：\n",
      "(10, 32, 16, 16)\n",
      "\n",
      "卷积层的输入边缘填充之后的第一个batch的第一个channel的前三行是：\n",
      "[[   0.            0.            0.        ]\n",
      " [   0.          228.16981617  231.87908912]\n",
      " [   0.          228.16981617  228.16981617]]\n",
      "卷积层输入数据的32个channel的map的3X3的小块：\n",
      "(10, 32, 3, 3)\n",
      "\n",
      "卷积层输入数据的第一个batch的第一个channel的map的3X3的小块：\n",
      "[[   0.            0.            0.        ]\n",
      " [   0.          228.16981617  231.87908912]\n",
      " [   0.          228.16981617  228.16981617]]\n",
      "\n",
      "第一个输入数据对应第一个输出数据的卷积核，类似于全连接中的W11：\n",
      "[[ 0.07717962 -1.19064496 -1.66535497]\n",
      " [ 1.25750646  1.80767035 -0.0525058 ]\n",
      " [-1.4591329   0.9129148   0.86170935]]\n",
      "\n",
      "卷积层输出数据的第一个batch的第一个channel的map的3X3的小块\n",
      "[[-1499.06910742     0.             0.        ]\n",
      " [    0.             0.             0.        ]\n",
      " [    0.             0.             0.        ]]\n"
     ]
    }
   ],
   "source": [
    "relu1_data = np.load('./data_pic/data_3_relu1[10-32-14-14].npy')\n",
    "print (\"卷积层的输入的shape是：\\n\"+str(relu1_data.shape))\n",
    "pad = 1\n",
    "in_data_pad = np.pad(relu1_data, ((0,), (0,), (pad,), (pad,)), mode='constant', constant_values=0) #边缘填充，这里上下左右各填一个像素\n",
    "print (\"\\n卷积层的输入边缘填充之后的shape是：\\n\"+str(in_data_pad.shape))\n",
    "print (\"\\n卷积层的输入边缘填充之后的第一个batch的第一个channel的前三行是：\\n\"+str(in_data_pad[:,:,0:3,0:3][0][0]))\n",
    "\n",
    "in_data_pad_masked = in_data_pad[:, :, 0:3, 0:3]\n",
    "print (\"卷积层输入数据的32个channel的map的3X3的小块：\")\n",
    "print (in_data_pad_masked.shape)\n",
    "print (\"\\n卷积层输入数据的第一个batch的第一个channel的map的3X3的小块：\")\n",
    "print (in_data_pad_masked[0][0])\n",
    "\n",
    "conv2_w = np.random.randn(16,32, 3, 3)    #w初值设置，随机产生标准正太分布范围内的数\n",
    "print (\"\\n第一个输入数据对应第一个输出数据的卷积核，类似于全连接中的W11：\")\n",
    "print (conv2_w[0][0])\n",
    "conv2_b = np.random.randn(16)\n",
    "conv2_out = np.zeros((10 , 16 , 14, 14))\n",
    "conv2_out[:, 0 , 0, 0] = np.sum(in_data_pad_masked * conv2_w[0, :, :, :], axis=(1,2,3))+ conv2_b[0]\n",
    "print (\"\\n卷积层输出数据的第一个batch的第一个channel的map的3X3的小块\")\n",
    "print (conv2_out[:,:,0:3,0:3][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上层传过来的残差top_diff的shape：\n",
      "(10, 16, 14, 14)\n",
      "\n",
      "上层传过来的残差top_diff的第一个残差的左上角3x3的值：\n",
      "[[  0.00000000e+00   1.64330032e-09   1.45613870e-08]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   6.06516134e-09   0.00000000e+00]]\n",
      "\n",
      "top_diff加pad之后的shape：\n",
      "(10, 16, 16, 16)\n",
      "\n",
      "上层传过来的残差top_diff的pad之后的第一个残差的左上角3x3的值：\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   1.64330032e-09]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "\n",
      "输入数据的shape：\n",
      "(10, 32, 14, 14)\n",
      "\n",
      "输入数据的加pad之后的shape：\n",
      "(10, 32, 16, 16)\n",
      "\n",
      "取输入数据的加pad之后的左上角3x3小块的shape：\n",
      "(10, 32, 3, 3)\n",
      "\n",
      "取输入数据的加pad之后第一个map的左上角3x3小块：\n",
      "[[   0.            0.            0.        ]\n",
      " [   0.          228.16981617  231.87908912]\n",
      " [   0.          228.16981617  228.16981617]]\n"
     ]
    }
   ],
   "source": [
    "# 反向传播\n",
    "residual = np.load(\"./data_pic/residual_7_maxpooling[10 16 14 14].npy\")\n",
    "print(\"上层传过来的残差top_diff的shape：\")\n",
    "print (residual.shape)\n",
    "print(\"\\n上层传过来的残差top_diff的第一个残差的左上角3x3的值：\")\n",
    "print (residual[:,:,0:3,0:3][0][0])\n",
    "residual_pad = np.pad(residual, ((0,), (0,), (1,), (1,)), mode='constant', constant_values=0)\n",
    "print (\"\\ntop_diff加pad之后的shape：\\n\"+str(residual_pad.shape))\n",
    "print(\"\\n上层传过来的残差top_diff的pad之后的第一个残差的左上角3x3的值：\")\n",
    "print (residual_pad[:,:,0:3,0:3][0][0])\n",
    "\n",
    "db = np.sum(residual, axis=(0, 2, 3))\n",
    "\n",
    "\n",
    "H_out = 14\n",
    "W_out = 14\n",
    "stride = 1\n",
    "HH = 3\n",
    "WW = 3\n",
    "N = 10\n",
    "F = 16\n",
    "C =32\n",
    "i = 0\n",
    "j = 0\n",
    "pad = 1\n",
    "lr=0.01\n",
    "reg = 0.75\n",
    "\n",
    "x_pad = np.pad(in_data, ((0,), (0,), (1,), (1,)), mode='constant', constant_values=0)\n",
    "x_pad_masked = x_pad[:, :, i * stride:i * stride + HH, j * stride:j * stride + WW]\n",
    "print (\"\\n输入数据的shape：\\n\"+str(in_data.shape))\n",
    "print (\"\\n输入数据的加pad之后的shape：\\n\"+str(x_pad.shape))\n",
    "print (\"\\n取输入数据的加pad之后的左上角3x3小块的shape：\\n\"+str(x_pad_masked.shape))\n",
    "print (\"\\n取输入数据的加pad之后第一个map的左上角3x3小块：\\n\"+str(x_pad_masked[0][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.对w求导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这里，求dw有两种求法：\n",
    "\n",
    "#### 1.原作者的求法：w_diff = pad(Bottom_data) 分块与top_diff中的每一个像素相乘（这里没有用到卷积）。具体例子请看博客：https://blog.csdn.net/weixin_37251044/article/details/81910932\n",
    "\n",
    "#### 2.我的求法：按照w_diff = pad(Bottom_data) 卷积 top_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "取输入数据的加pad之后的左上角3x3小块的shape：\n",
      "(10, 32, 3, 3)\n",
      "\n",
      "对w求导的diff_w的shape：\n",
      "(16, 32, 3, 3)\n",
      "\n",
      "对w求导的diff_w的第一个dw的值：\n",
      "[[ -8.46562862e-05  -3.35537174e-05  -4.15742318e-05]\n",
      " [ -7.83996051e-05  -5.53166854e-05  -8.53559591e-06]\n",
      " [ -6.20210835e-05  -5.94926942e-05  -3.16911145e-05]]\n",
      "(10, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# 1.原作者的求法：\n",
    "dw_1 = np.zeros_like(con_w)\n",
    "\n",
    "for i in range(H_out):\n",
    "            for j in range(W_out):\n",
    "                x_pad_masked = x_pad[:, :, i * stride:i * stride + HH, j * stride:j * stride + WW]\n",
    "                for k in range(F):  # compute dw\n",
    "                    dw_1[k, :, :, :] += np.sum(x_pad_masked * (residual[:, k, i, j])[:, None, None, None], axis=0)\n",
    "                \n",
    "                \n",
    "\n",
    "print (\"\\n取输入数据的加pad之后的左上角3x3小块的shape：\\n\"+str(x_pad_masked.shape))\n",
    "print (\"\\n对w求导的diff_w的shape：\\n\"+str(dw_1.shape))\n",
    "print (\"\\n对w求导的diff_w的第一个dw的值：\\n\"+str(dw_1[0][0]))\n",
    "\n",
    "print ((residual[:,0,0,0])[:,None,None,None].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "对w求导的diff_w的shape：\n",
      "(16, 32, 3, 3)\n",
      "\n",
      "对w求导的diff_w的第一个dw的值：\n",
      "[[ -8.46562862e-05  -3.35537174e-05  -4.15742318e-05]\n",
      " [ -7.83996051e-05  -5.53166854e-05  -8.53559591e-06]\n",
      " [ -6.20210835e-05  -5.94926942e-05  -3.16911145e-05]]\n"
     ]
    }
   ],
   "source": [
    "# 2.我的求法：\n",
    "k = 0\n",
    "dw_2 = np.zeros_like(con_w)\n",
    "for m in range(HH):\n",
    "            for n in range(WW):\n",
    "                x_pad_masked_d = x_pad[:, :, m * stride:m * stride + H_out, n * stride:n * stride + W_out]\n",
    "                for k in range(F):\n",
    "                    for p in range(C):\n",
    "                        dw_2[k, p, m, n] = np.sum(x_pad_masked_d[:,p,:,:] * residual[:, k, :, :], axis=(0,1,2)) \n",
    "\n",
    "print (\"\\n对w求导的diff_w的shape：\\n\"+str(dw_2.shape))\n",
    "print (\"\\n对w求导的diff_w的第一个dw的值：\\n\"+str(dw_2[0][0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 说明:这里两个方法求得的dw[0 0 0 0]位置上的数值都是-0.00025397。从而证明了两种方法都正确。\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.对输入数据x求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dx_pad的shape：\n",
      "(10, 32, 16, 16)\n",
      "\n",
      "dx_pad[10 32 16 16]中batch_0位置上32个map的左上角3x3的小块：\n",
      "[[ -5.95674081e-09  -5.51905160e-09  -1.07998587e-08]\n",
      " [ -5.30157577e-09  -3.30199066e-09   7.88567986e-09]\n",
      " [  2.23308231e-08   1.09127648e-08   3.55374539e-08]]\n",
      "\n",
      "dx的shape：\n",
      "(10, 32, 14, 14)\n",
      "\n",
      "dx[10 32 14 14]中batch_0位置上32个map的左上角3x3的小块：\n",
      "[[ -3.30199066e-09   7.88567986e-09   8.58298651e-09]\n",
      " [  1.09127648e-08   3.55374539e-08  -1.47638047e-08]\n",
      " [ -2.19378633e-08  -1.57148127e-08   3.90876291e-08]]\n"
     ]
    }
   ],
   "source": [
    "# 1.dx计算方法一:点积法\n",
    "\n",
    "\n",
    "n = 0\n",
    "#print ((residual_pad[n, :, i,j])[:, None, None, None].shape)\n",
    "\n",
    "\n",
    "dx_pad = np.zeros_like(x_pad)\n",
    "\n",
    "for i in range(H_out):\n",
    "    for j in range(W_out):\n",
    "        x_pad_masked = x_pad[:, :, i * stride:i * stride + HH, j * stride:j * stride + WW]\n",
    "        for n in range(N):  # compute dx_pad\n",
    "            dx_pad[n, :, i * stride:i * stride + HH, j * stride:j * stride + WW] += np.sum((con_w[:, :, :, :] * (residual[n, :, i,j])[:, None, None, None]), axis=0)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "#for n in range(N):\n",
    "#    dx_pad[n, :, i * stride:i * stride + HH, j * stride:j * stride + WW] += np.sum((con_w[:, :, :, :] * (residual[n, :, i,j])[:, None, None, None]), axis=0)\n",
    "print (\"\\ndx_pad的shape：\")\n",
    "print (dx_pad.shape)\n",
    "print (\"\\ndx_pad[10 32 16 16]中batch_0位置上32个map的左上角3x3的小块：\")\n",
    "print (dx_pad[:,:,0:3,0:3][0][0])\n",
    "dx = np.zeros_like(in_data)\n",
    "dx[:,:,:,:] = dx_pad[:, :, pad:-pad, pad:-pad]\n",
    "print (\"\\ndx的shape：\")\n",
    "print (dx.shape)\n",
    "print (\"\\ndx[10 32 14 14]中batch_0位置上32个map的左上角3x3的小块：\")\n",
    "print (dx[:,:,0:3,0:3][0][0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "w 的第一个3x3的小块：\n",
      "[[-1.04843514 -0.82283949 -0.7007134 ]\n",
      " [ 1.17047538  0.48789643  0.90273564]\n",
      " [ 0.1461493  -0.15088991  0.15200268]]\n",
      "\n",
      "rot180_w的shape：\n",
      "(16, 32, 3, 3)\n",
      "\n",
      "rot180_w的第一个3x3的小块：\n",
      "[[ 0.15200268 -0.15088991  0.1461493 ]\n",
      " [ 0.90273564  0.48789643  1.17047538]\n",
      " [-0.7007134  -0.82283949 -1.04843514]]\n",
      "\n",
      "top_diff加pad之后的shape：\n",
      "(10, 16, 16, 16)\n",
      "\n",
      "residual_pad_masked的shape：\n",
      "(10, 16, 3, 3)\n",
      "\n",
      "residual_pad_masked的左上角3X3小块：\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "\n",
      "dx_2的shape：\n",
      "(10, 32, 14, 14)\n",
      "\n",
      "dx_2[10 32 14 14]中batch_0位置上32个map的左上角3x3的小块：\n",
      "[[ -3.30199066e-09   7.88567986e-09   8.58298651e-09]\n",
      " [  1.09127648e-08   3.55374539e-08  -1.47638047e-08]\n",
      " [ -2.19378633e-08  -1.57148127e-08   3.90876291e-08]]\n"
     ]
    }
   ],
   "source": [
    "# dx计算方法二：rot180卷积法\n",
    "rot_w = np.rot90(con_w,2,(2,3)) #第一个2是逆时针旋转90度2次，也就是180度。（2,3）表示旋转con_w的第（2,3）维。\n",
    "print (\"\\nw 的第一个3x3的小块：\\n\"+str(con_w[:,:,0:3,0:3][0][0]))\n",
    "print (\"\\nrot180_w的shape：\\n\"+str(rot_w.shape))\n",
    "print (\"\\nrot180_w的第一个3x3的小块：\\n\"+str(rot_w[:,:,0:3,0:3][0][0]))\n",
    "# 说明：这里说明旋转正确，不知道为啥原作者觉得不旋转\n",
    "\n",
    "h = 0\n",
    "print (\"\\ntop_diff加pad之后的shape：\\n\"+str(residual_pad.shape))\n",
    "\n",
    "\n",
    "residual_pad_masked = residual_pad[:, :, i*stride:i*stride+HH, j*stride:j*stride+WW]\n",
    "print (\"\\nresidual_pad_masked的shape：\\n\"+str(residual_pad_masked.shape))\n",
    "print (\"\\nresidual_pad_masked的左上角3X3小块：\\n\"+str(residual_pad_masked[0][0]))\n",
    "\n",
    "dx_2 = np.zeros_like(in_data)\n",
    "\n",
    "pad_diff_H = HH - (1 + pad)\n",
    "pad_diff_W = WW - (1 + pad)\n",
    "residual_pad = np.pad(residual, ((0,), (0,), (pad_diff_H,), (pad_diff_W,)), mode='constant', constant_values=0)\n",
    "for i in range(H_out):\n",
    "    for j in range(W_out):\n",
    "        residual_pad_masked = residual_pad[:, :, i*stride:i*stride+HH, j*stride:j*stride+WW]        \n",
    "        for h in range(C):\n",
    "            dx_2[:, h , i, j] = np.sum(residual_pad_masked[:,:,:,:] * rot_w[:, h, :, :], axis=(1,2,3))\n",
    "print (\"\\ndx_2的shape：\")\n",
    "print (dx_2.shape)\n",
    "print (\"\\ndx_2[10 32 14 14]中batch_0位置上32个map的左上角3x3的小块：\")\n",
    "print (dx_2[:,:,0:3,0:3][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结：两个计算结果一致，说明我们的推导是正确的\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.更新w和b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更新后的W：\n",
      "[[ 0.24096305 -0.11422576 -0.11721828]\n",
      " [-0.83480148  0.01053807 -0.18909859]\n",
      " [-1.14731769 -0.81641328 -0.70336186]]\n",
      "\n",
      "更新后的b：\n",
      "[-0.06972303 -0.04964828  0.03469369 -1.49293904 -1.20007582 -0.95382245\n",
      "  0.3049204   0.14409858  0.96337989 -1.26748569  0.73992418 -0.66945493\n",
      "  0.31008377  0.76122079 -2.06858212  0.40428955]\n"
     ]
    }
   ],
   "source": [
    "prev_gradient_w = con_w\n",
    "w = np.random.randn(16,32, 3, 3)\n",
    "b = np.random.randn(16)\n",
    "w -= lr * (dw_1 + prev_gradient_w * reg)\n",
    "b -= lr * db\n",
    "prev_gradient_w = w\n",
    "print (\"更新后的W：\")\n",
    "print (w[:,:,0:3,0:3][0][0])\n",
    "print (\"\\n更新后的b：\")\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其它:数组旋转180度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "将矩阵逆时针旋转90度\n",
      "[[2 5 8]\n",
      " [1 4 7]\n",
      " [0 3 6]]\n",
      "再将矩阵逆时针旋转90度\n",
      "[[8 7 6]\n",
      " [5 4 3]\n",
      " [2 1 0]]\n",
      "将矩阵逆时针旋转180度\n",
      "[[8 7 6]\n",
      " [5 4 3]\n",
      " [2 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ac = np.arange(0,9,1).reshape(3,3)\n",
    "print (ac)\n",
    "dc = np.rot90(ac,1)\n",
    "print (\"将矩阵逆时针旋转90度\")\n",
    "print (dc)\n",
    "ec = np.rot90(dc,1)\n",
    "print (\"再将矩阵逆时针旋转90度\")\n",
    "print (ec)\n",
    "fc = np.rot90(ac,2)\n",
    "print (\"将矩阵逆时针旋转180度\")\n",
    "print (fc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy的点乘："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]]\n",
      "\n",
      " [[ 6  7  8]\n",
      "  [ 9 10 11]]]\n",
      "[[[ 0.]]\n",
      "\n",
      " [[ 0.]]]\n",
      "[[[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]]\n",
      "[[ 6  8 10]\n",
      " [12 14 16]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ac = np.arange(0,12,1).reshape(2,2,3)\n",
    "print (ac)\n",
    "bc = np.zeros((2, ))[:,None,None]\n",
    "print (bc)\n",
    "print (ac*bc)\n",
    "print (np.sum(ac,axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99325177301\n",
      "说明：numpy的log函数默认是以10为底的\n"
     ]
    }
   ],
   "source": [
    "print (np.log(2.7))\n",
    "print (\"说明：numpy的log函数默认是以10为底的\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
